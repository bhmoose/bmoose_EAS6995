{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cb8b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import required packages\n",
    "import numpy as np, xarray as xr, matplotlib.pyplot as plt, xradar as xd, pyart, pandas as pd, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cc8f6",
   "metadata": {},
   "source": [
    "Get Severe Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8ae4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_based_warnings = []\n",
    "\n",
    "#Iterate through CSV files containing National Weather Service warning times for each county, concatenate into DataFrame\n",
    "for filename in [r'C:\\Users\\benja\\Downloads\\vtec_ALC' + str(num).zfill(3) + '_20150101_20250505.csv' for num in [7, 121, 117, 115, 37, 21, 73]]:\n",
    "    county_based_warnings.append(pd.read_csv(filename))\n",
    "all_warnings = pd.concat(county_based_warnings)\n",
    "\n",
    "#Select severe thunderstorm warnings, drop warnings with duplicate issuance times\n",
    "all_stws = all_warnings[all_warnings['name'] == 'Severe Thunderstorm Warning'].reset_index(drop = True)\n",
    "all_swts_noduplicates = all_stws.drop_duplicates(subset=['iso_issued'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0c1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Error retrieving scans for index 1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Import package to get radar scans from AWS (from https://nexradaws.readthedocs.io/en/latest/Tutorial.html#Get-available-radars-in-a-given-year,-month,-and-day)\n",
    "import nexradaws\n",
    "conn = nexradaws.NexradAwsInterface()\n",
    "\n",
    "all_grid_xarrays = []\n",
    "radar_objects = []\n",
    "#Iterate through issuance times of severe thunderstorm warnings\n",
    "for idx, timeval in enumerate(pd.to_datetime(all_swts_noduplicates['iso_issued'][0:])):\n",
    "    print(idx + 0)\n",
    "    try:\n",
    "        #Get radar scan times within a 14 minute range of warning issuance time\n",
    "        scans = conn.get_avail_scans_in_range(timeval - datetime.timedelta(minutes = 7), timeval + datetime.timedelta(minutes = 7), 'KBMX')\n",
    "        filename = \"s3://noaa-nexrad-level2/\" + scans[0].awspath + \"/\" + scans[0].filename\n",
    "        \n",
    "        #Read first radar scan file in 14-minute range (https://arm-doe.github.io/pyart/examples/io/plot_nexrad_data_aws.html)\n",
    "        radar = pyart.io.read_nexrad_archive(filename)\n",
    "        \n",
    "        #Grid radar scan file to 150kmx150kmx10km grid, at 400x400x11 resolution (https://arm-doe.github.io/pyart/examples/xradar/plot_grid_xradar.html#sphx-glr-examples-xradar-plot-grid-xradar-py)\n",
    "        grid = pyart.map.grid_from_radars(\n",
    "            (radar,),\n",
    "            grid_shape=(11, 1000, 1000),\n",
    "            grid_limits=(\n",
    "                (0.0, 10_000),\n",
    "                (-150_000.0, 150_000.0),\n",
    "                (-150_000, 150_000.0),\n",
    "            ), min_radius = 1000\n",
    "        )\n",
    "\n",
    "        #Convert gridded radar file into xarray, save file\n",
    "        grid_xr = grid.to_xarray()\n",
    "        grid_xr.to_netcdf('radar_file_' + str(idx + 0) + '.nc')\n",
    "    except:\n",
    "        print('Error retrieving scans for index ' + str(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c617ad9",
   "metadata": {},
   "source": [
    "Get Random Non-Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b8d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_swts_noduplicates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Get list of dates with severe thunderstorm warnings\n",
    "dates_w_severe = [pd.to_datetime(all_swts_noduplicates['iso_issued'][i]).date() for i in range(len(all_swts_noduplicates))]\n",
    "\n",
    "#Get range of hours from the first to last severe thunderstorm warning time in the dataset\n",
    "dr = pd.date_range(pd.to_datetime(all_swts_noduplicates['iso_issued'][0]), \n",
    "              pd.to_datetime(all_swts_noduplicates['iso_issued'][len(all_swts_noduplicates) - 1]), \n",
    "              freq=datetime.timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "#Iterate for as many iterations as the number of severe thunderstorm warning cases\n",
    "while idx < len(all_swts_noduplicates):\n",
    "\n",
    "    #Get random indices of dates in daterange, get associated date\n",
    "    randidx = np.random.randint(len(dr))\n",
    "    dateval = dr[randidx]\n",
    "\n",
    "    #Get date from 1 hour before and 1 hour after dateval\n",
    "    p1hr_date = (dateval + datetime.timedelta(hours = 1)).date()\n",
    "    m1hr_date = (dateval - datetime.timedelta(hours = 1)).date()\n",
    "\n",
    "    #If no severe thunderstorm warnings occur on days within 1 hour of selected hour..\n",
    "    if (dateval.date() not in dates_w_severe) and (p1hr_date not in dates_w_severe) and (m1hr_date not in dates_w_severe): \n",
    "        try:\n",
    "            #Get radar scan times within a 14 minute range of selected time\n",
    "            scans = conn.get_avail_scans_in_range(dateval - datetime.timedelta(minutes = 7), dateval + datetime.timedelta(minutes = 7), 'KBMX')\n",
    "            filename = \"s3://noaa-nexrad-level2/\" + scans[0].awspath + \"/\" + scans[0].filename\n",
    "\n",
    "            #Read first radar scan file in 14-minute range\n",
    "            radar = pyart.io.read_nexrad_archive(filename)\n",
    "\n",
    "            #Grid radar scan file to 150kmx150kmx10km grid, at 400x400x11 resolution\n",
    "            grid = pyart.map.grid_from_radars(\n",
    "                (radar,),\n",
    "                grid_shape=(11, 400, 400),\n",
    "                grid_limits=(\n",
    "                    (0.0, 10_000),\n",
    "                    (-150_000.0, 150_000.0),\n",
    "                    (-150_000, 150_000.0),\n",
    "                ), min_radius = 1000\n",
    "            )\n",
    "\n",
    "            #Convert gridded radar file into xarray, save file\n",
    "            grid_xr = grid.to_xarray()\n",
    "            grid_xr.to_netcdf('null_radar_file_' + str(idx + 0) + '.nc')\n",
    "            print('Successfully retrieved null scan with index ' + str(idx) + ' for ' + str(dateval))\n",
    "            idx += 1\n",
    "        except:\n",
    "            print('Error retrieving scans')\n",
    "    else:\n",
    "        print('Selected date ' + str(dateval) + ' in severe storm date range, skipping')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6fb88",
   "metadata": {},
   "source": [
    "Get Thunderstorm Non-Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in spreadsheet containing times when thunderstorms were reported at ASOS stations within region of interest\n",
    "tstm_times = pd.read_csv(r\"C:\\Users\\benja\\Downloads\\tstm_times.csv\", header=None)\n",
    "tstm_times.columns = ['DateTime']\n",
    "tstm_times = pd.to_datetime(tstm_times['DateTime'])\n",
    "\n",
    "#Get dates on which thunderstorms occurred\n",
    "tstm_dates = list(np.unique([tstm_times[i].date() for i in range(len(tstm_times))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_dates = []\n",
    "idx = 0\n",
    "time_idx = 0\n",
    "#Iterate for as many iterations as the number of severe thunderstorm warning cases\n",
    "while idx < len(all_swts_noduplicates):\n",
    "    #Get time of thunderstorm report, times an hour before and an hour after\n",
    "    dateval = tstm_times[time_idx]\n",
    "    p1hr_date = (dateval + datetime.timedelta(hours = 1)).date()\n",
    "    m1hr_date = (dateval - datetime.timedelta(hours = 1)).date()\n",
    "    \n",
    "    #If no severe storms on date (or +- 1 hour date) and date has not already been selected, get data for selected time\n",
    "    if (dateval.date() not in dates_w_severe) and (p1hr_date not in dates_w_severe) and (m1hr_date not in dates_w_severe): \n",
    "        if (dateval.date() not in previous_dates) and (p1hr_date not in previous_dates) and (m1hr_date not in previous_dates):\n",
    "            try:\n",
    "                #Get radar scan times within a 14 minute range of selected time\n",
    "                scans = conn.get_avail_scans_in_range(dateval - datetime.timedelta(minutes = 7), dateval + datetime.timedelta(minutes = 7), 'KBMX')\n",
    "                filename = \"s3://noaa-nexrad-level2/\" + scans[0].awspath + \"/\" + scans[0].filename\n",
    "                \n",
    "                #Read first radar scan file in 14-minute range\n",
    "                radar = pyart.io.read_nexrad_archive(filename)\n",
    "                \n",
    "                #Grid radar scan file to 150kmx150kmx10km grid, at 400x400x11 resolution\n",
    "                grid = pyart.map.grid_from_radars(\n",
    "                    (radar,),\n",
    "                    grid_shape=(11, 400, 400),\n",
    "                    grid_limits=(\n",
    "                        (0.0, 10_000),\n",
    "                        (-150_000.0, 150_000.0),\n",
    "                        (-150_000, 150_000.0),\n",
    "                    ), min_radius = 1000\n",
    "                )\n",
    "    \n",
    "                #Convert gridded radar file into xarray, save file\n",
    "                grid_xr = grid.to_xarray()\n",
    "                grid_xr.to_netcdf('tstm_nonevent_radar_file_' + str(idx + 0) + '.nc')\n",
    "                print('Successfully retrieved tstm nonevent scan with index ' + str(idx) + ' for ' + str(dateval))\n",
    "                previous_dates.append(dateval.date())\n",
    "                idx += 1\n",
    "            except:\n",
    "                print('Error retrieving scans')\n",
    "        else:\n",
    "            print('Selected date ' + str(dateval) + ' already sampled, skipping')\n",
    "    else:\n",
    "        print('Selected date ' + str(dateval) + ' in severe storm date range, skipping')\n",
    "    time_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab3a018",
   "metadata": {},
   "source": [
    "Get Rain Non-Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get times with rain reports at at least one ASOS station in region of interest\n",
    "strat_times = pd.read_csv(r\"C:\\Users\\benja\\Downloads\\stratiform_times.csv\", header=None)\n",
    "strat_times.columns = ['DateTime']\n",
    "strat_times = pd.to_datetime(strat_times['DateTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098321fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_dates = []\n",
    "idx = 0\n",
    "time_idx = 0\n",
    "#Iterate for as many iterations as the number of severe thunderstorm warning cases\n",
    "while idx < len(all_swts_noduplicates):\n",
    "    #Get time of thunderstorm report, times an hour before and an hour after\n",
    "    dateval = strat_times[time_idx]\n",
    "    p1hr_date = (dateval + datetime.timedelta(hours = 1)).date()\n",
    "    m1hr_date = (dateval - datetime.timedelta(hours = 1)).date()\n",
    "    \n",
    "    #If no severe storms or thunderstorms on date (or +- 1 hour date) and date has not already been selected, get data for selected time\n",
    "    if (dateval.date() not in dates_w_severe) and (p1hr_date not in dates_w_severe) and (m1hr_date not in dates_w_severe): \n",
    "        if (dateval.date() not in tstm_dates) and (p1hr_date not in tstm_dates) and (m1hr_date not in tstm_dates):\n",
    "            if (dateval.date() not in previous_dates) and (p1hr_date not in previous_dates) and (m1hr_date not in previous_dates):\n",
    "                try:\n",
    "                    #Get radar scan times within a 14 minute range of selected time\n",
    "                    scans = conn.get_avail_scans_in_range(dateval - datetime.timedelta(minutes = 7), dateval + datetime.timedelta(minutes = 7), 'KBMX')\n",
    "                    filename = \"s3://noaa-nexrad-level2/\" + scans[0].awspath + \"/\" + scans[0].filename\n",
    "                    \n",
    "                    #Read first radar scan file in 14-minute range\n",
    "                    radar = pyart.io.read_nexrad_archive(filename)\n",
    "                    \n",
    "                    #Grid radar scan file to 150kmx150kmx10km grid, at 400x400x11 resolution\n",
    "                    grid = pyart.map.grid_from_radars(\n",
    "                        (radar,),\n",
    "                        grid_shape=(11, 400, 400),\n",
    "                        grid_limits=(\n",
    "                            (0.0, 10_000),\n",
    "                            (-150_000.0, 150_000.0),\n",
    "                            (-150_000, 150_000.0),\n",
    "                        ), min_radius = 1000\n",
    "                    )\n",
    "                    \n",
    "                    #Convert gridded radar file into xarray, save file\n",
    "                    grid_xr = grid.to_xarray()\n",
    "                    grid_xr.to_netcdf('stratiform_nonevent_radar_file_' + str(idx + 0) + '.nc')\n",
    "                    print('Successfully retrieved tstm nonevent scan with index ' + str(idx) + ' for ' + str(dateval))\n",
    "                    previous_dates.append(dateval.date())\n",
    "                    idx += 1\n",
    "                except:\n",
    "                    print('Error retrieving scans')\n",
    "            else:\n",
    "                print('Selected date ' + str(dateval) + ' already sampled, skipping')\n",
    "        else:\n",
    "            print('Selected date ' + str(dateval) + ' in nonsevere thunderstorm date range, skipping')\n",
    "    else:\n",
    "        print('Selected date ' + str(dateval) + ' in severe storm date range, skipping')\n",
    "    time_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eas6995",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
